function [y1] = NN_PSK_3dB(x1)
% This neural network is trained at 3dB to detect the order of PSK
% modulations
%
% Generated by Neural Network Toolbox function genFunction, 30-Nov-2016 01:33:57.
%
% [y1] = myNeuralNetworkFunction(x1) takes these arguments:
%   x = 13xQ matrix, input #1
% and returns:
%   y = 3xQ matrix, output #1
% where Q is the number of samples.

%#ok<*RPMT0>

% ===== NEURAL NETWORK CONSTANTS =====

% Input 1
x1_step1_xoffset = [-0.316677190447545;-1.30367502846666;1.15651490131963;-2.09889376263168;-2.09352477259443;-1.85267880723471;-0.914162813958581;-2.07135862832539;1.37893183575465;-1.19575097537975;0.854362370896577;-18.2907200484466;3.68950308106008];
x1_step1_gain = [1.334030947885;0.357526897135885;0.251040245792733;0.700892696944244;0.706019637568554;0.232839197086955;0.56085059962512;0.206284262715366;0.0400441319295313;0.108466720249256;0.04303956398033;0.0287357252767601;0.149071507091837];
x1_step1_ymin = -1;

% Layer 1
b1 = [-1.7138589199697298;-0.13677021186249785;1.2292140274394463];
IW1_1 = [1.6137137246922502 -0.58186621457552334 0.36108000215816455 0.77576616488327943 1.2489934048997302 0.076811901460823465 -0.13521797047069337 -0.20345812521688483 -0.31148435352977444 0.1623058062766887 -0.65544906251333923 0.4221591225246985 -0.71160422451621619;-2.9777675630704632 0.71123719222049997 -0.12107957346665614 -0.66151583148207849 0.54694101325864619 0.25763167550567545 0.27580912782618217 -0.15493892280936405 0.28701766807022083 -0.63973213885905611 -0.75951150370078613 0.22961652955477696 -0.094998623797876242;0.58344974730849308 0.14758424773793155 0.47738952604474338 -0.29876732739159234 -0.88068239546896065 -0.41873205697543758 1.0094770042831867 0.3939828928954322 0.84442956858521878 0.011119204104992947 0.4626007584838791 0.079191946150063072 1.1528365933947387];

% Layer 2
b2 = [-0.31342199261546283;-0.42482435564592447;1.4977344580509842];
LW2_1 = [-3.9858653843146965 -3.2250245668715722 3.1772014497534919;5.7650208866771431 -3.7306773753174722 -2.2166412778434106;-0.90445571539316094 6.208253712084721 -2.0508233261816193];

% ===== SIMULATION ========

% Dimensions
Q = size(x1,2); % samples

% Input 1
xp1 = mapminmax_apply(x1,x1_step1_gain,x1_step1_xoffset,x1_step1_ymin);

% Layer 1
a1 = tansig_apply(repmat(b1,1,Q) + IW1_1*xp1);

% Layer 2
a2 = softmax_apply(repmat(b2,1,Q) + LW2_1*a1);

% Output 1
y1 = a2;
end

% ===== MODULE FUNCTIONS ========

% Map Minimum and Maximum Input Processing Function
function y = mapminmax_apply(x,settings_gain,settings_xoffset,settings_ymin)
y = bsxfun(@minus,x,settings_xoffset);
y = bsxfun(@times,y,settings_gain);
y = bsxfun(@plus,y,settings_ymin);
end

% Competitive Soft Transfer Function
function a = softmax_apply(n)
nmax = max(n,[],1);
n = bsxfun(@minus,n,nmax);
numer = exp(n);
denom = sum(numer,1);
denom(denom == 0) = 1;
a = bsxfun(@rdivide,numer,denom);
end

% Sigmoid Symmetric Transfer Function
function a = tansig_apply(n)
a = 2 ./ (1 + exp(-2*n)) - 1;
end
